This section contrasts prevailing assistant-style systems with constraint-based cognitive architectures and introduces the Reflectiveâ€“Ethical Engine (REE) as an illustrative model.

\subsection*{Assistant-style systems and externalised constraint}
Most deployed assistants are optimised for responsiveness and task completion. Safety is typically addressed through external mechanisms (filters, policies, monitoring), which are necessary but operate around the cognitive core.

\subsection*{Constraint-based cognition}
Constraint-based architectures evaluate and select among candidate trajectories, conditioning selection on coherence under continued interaction. Ethical stability emerges because trajectories that violate coherence constraints fail to remain viable.

\subsection*{REE as an illustrative model}
REE comprises fast predictive generation, deep temporal synthesis, and constrained trajectory selection within a unified latent representation. Action selection is conditioned on viability under continuation, disfavoring exploitation, deception, and premature certainty even when short-term gains are available.
