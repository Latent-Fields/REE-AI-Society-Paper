4. Ethics as Stability

This section advances the paper’s central normative claim: ethics is best understood not as a set of externally imposed rules or values, but as a stability condition required for cognition to remain viable over time under uncertainty. On this view, ethical behaviour is not an optional overlay on cognition, but a constitutive requirement for sustained, coherent agency (Dennett 1987; Floridi 2013).

4.1 Cognition under irreducible uncertainty

Cognition, whether human or artificial, operates under conditions of irreducible uncertainty. Agents must act without privileged access to ground truth, complete information, or guaranteed outcomes. Viable cognition is therefore not defined by correspondence to fixed truths, but by the ability to maintain coherent input–output behaviour across time, revision, and interaction (Friston 2010).

Under these conditions, cognition must balance multiple competing demands: responsiveness to new information, continuity of identity and intention, and coordination with others. Systems that resolve uncertainty too aggressively may achieve short-term coherence but become brittle, escalating error when initial assumptions fail. Systems that fail to stabilise uncertainty at all become paralysed. Viability lies in maintaining coherence without collapse.

4.2 Ethical constraints as coherence requirements

Ethical constraints can be reconceptualised as coherence requirements operating across multiple dimensions of cognition. At minimum, these include:
4.2.1 Temporal coherence, ensuring that present actions remain compatible with future revision and responsibility.
4.2.2 Self–other coherence, maintaining consistency between one’s own goals and the recognition of others as similarly situated agents rather than mere instruments.
4.2.3 Epistemic coherence, preserving openness to uncertainty, error, and correction rather than enforcing premature closure.

When these constraints are respected, cognition remains adaptable, socially embedded, and capable of learning. When they are violated, cognition becomes brittle and escalating: commitments harden, alternatives collapse, and behaviour increasingly diverges from both social norms and long-horizon self-interest. Ethical failure, on this account, is not primarily a matter of immoral preference, but of loss of stabilising coherence.

4.3 From normative claim to architectural requirement

If ethical stability is a necessary condition for viable cognition under uncertainty, then it cannot be reliably maintained through external oversight alone. Systems designed to amplify cognition—particularly those that enhance internal coherence, planning capacity, or narrative integration—must embody stabilising constraints within their internal organisation.

This reframes the ethics of artificial intelligence from a problem of rule enforcement or value alignment to a problem of architectural viability. Artificial intelligence systems intended as cognitive augments must not only generate coherent outputs, but support forms of coherence that remain stable across time, uncertainty, and social interaction. The next section examines how prevailing assistant-style architectures fall short of this requirement and introduces a constraint-based alternative as an illustrative model.

